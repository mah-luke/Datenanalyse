library(ggplot2)
ggplot(data=Diamond, aes(carat, price,colour=clarity)) + geom_point( size=1)
# overview of price carat and clarity
library(ggplot2)
ggplot(data=Diamond, aes(carat, price,colour=clarity)) + geom_point( size=1)
As we can see in the graph above, the price seems to increase quadratically compared to the amount of carats. Now 2 steps need to be done to make price independent of carat: we need to use price/carat as unit since the price goes up with every carat. Secondly we need need to remove the increase of price/carat. This comes from the lower supply for bigger diamonds. Since very clear diamonds are very rare for bigger sizes, they are way less common for higher carat sizes. To handle this problem we can divide another time by carat and get price/carat per carat which removes the influence of bigger diamonds being worth more per carat.
```{r}
ggplot(data=Diamond, aes(carat, price/carat,colour=clarity)) + geom_point(size=1)
ggplot(data=Diamond, aes(carat, price/carat,colour=clarity)) + geom_point(size=1)
```{r}
set.seed(69)
library("StatDA")
data(chorizon)
pt <- chorizon$Pt
length(pt) # amount of values
length(pt[pt %in% 0.25]) # amount of values = 0.25
ptRem <- pt[!pt %in% 0.25] # Removes the 0.25 values
ptRem <- ptRem[ptRem < 3] # Removes all values above 5
ptLog <- log(pt) # transforms to log()
ptRemLog <- log(ptRem) # transforms to log()
par(mfrow = c (2,2))
hist(pt)
hist(ptLog)
hist(ptRem)
hist(ptRemLog)
par(mfrow = c (2,2))
hist(pt, breaks="FD")
hist(ptLog, breaks="FD")
hist(ptRem, breaks="FD")
hist(ptRemLog, breaks="FD")
br <- seq(0,10,2)
par(mfrow = c (1,2))
hist(pt[pt < 10], breaks=br)
hist(ptRem, breaks=br)
gaussian <- density(pt, kernel="gaussian")
cosine <- density(pt, kernel="cosine")
gaussian
cosine
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5)); lines(gaussian, col="red"); lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
par(mfrow= c(2,2))
qpplot.das(pt)
qpplot.das(ptLog)
qpplot.das(ptRem)
qpplot.das(ptRemLog)
install.packages("Ecdat")
library("Ecdat")
data(Diamond)
clarity <- Diamond$clarity
carat <- Diamond$carat
price <- Diamond$price
# overview of price carat and clarity
library(ggplot2)
ggplot(data=Diamond, aes(carat, price,colour=clarity)) + geom_point( size=1)
ggplot(data=Diamond, aes(carat, price/carat,colour=clarity)) + geom_point(size=1)
ggplot(data=Diamond, aes(carat, price/carat,colour=clarity)) + geom_point(size=1)
```{r}
``` {r}
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) + geom_point( size=1) + geom_smooth(method='lm')
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) + geom_point( size=1) + geom_smooth(method='lm', se=FALSE)
ggplot(data=Diamond, aes(carat,(price/carat^1.7), colour=clarity)) + geom_point( size=1) + geom_smooth(method='lm', se=FALSE)
ggplot(data=Diamond, aes(carat,(price/carat^1.5), colour=clarity)) + geom_point( size=1) + geom_smooth(method='lm', se=FALSE)
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) + geom_point( size=1) + geom_smooth(method='lm', se=FALSE)
ggplot(data=Diamond, aes(carat,(price/carat^1.65), colour=clarity)) + geom_point( size=1) + geom_smooth(method='lm', se=FALSE)
ggplot(data=Diamond, aes(carat,(price/carat^1.62), colour=clarity)) + geom_point( size=1) + geom_smooth(method='lm', se=FALSE)
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) + geom_point( size=1) + geom_smooth(method='lm', se=FALSE)
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) + geom_point( size=1) + geom_smooth(method='lmrobust', se=FALSE)
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) + geom_point( size=1) + geom_smooth(method='lmr', se=FALSE)
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) + geom_point( size=1) + geom_smooth(method='lm', se=FALSE)
install.packages("Ecdat")
install.packages("Ecdat")
qpplot.das(pt, xlabel = "pt")
set.seed(69)
library("StatDA")
The histogram with the Friedman-Diaconis method works best for my data because the outliers increase the width of the intervals which reduces the detail to see any possible distributions.
The fixed bin width of 2 is not ideal because important details get lost. Even more details get lost than in the standard interval method from Sturges.
When transforming to log, a potential normal distribution of the values from -0.5 to 0.7 can be spotted but is rather unlikely for the whole set because approximately half of the values is 0.25.
### Density approximation:
The cosine kernel would be more appropriate because there we can see the 'dip' between the many 0.25 values and the rest of the distribution that follows more of a normal distribution if transformed with log. On the gaussian kernel this fact is not included and would generate more generic datasets where this bump would be not as strong as in the cosine kernel.
On the other hand the gaussian kernel represents the extreme peak at 0.25 way more accurate than the cosine. Depending on the usecase both kernels have their own strengths for this dataset.
Below there are some extra qpplots to show the possibility of a normal distribution of the values in the interval (0.25,3].
``` {r}
par(mfrow= c(2,2))
qpplot.das(pt, xlabel = "pt")
qpplot.das(ptLog)
qpplot.das(ptRem)
qpplot.das(ptRemLog)
par(mfrow= c(2,2))
qpplot.das(pt, xlabel = "pt")
## 2nd Example:
``` {r}
library("Ecdat")
library("Ecdat")
data(Diamond)
clarity <- Diamond$clarity
carat <- Diamond$carat
price <- Diamond$price
qpplot.das(pt, xlab = "pt")
gaussian <- density(pt, kernel= "gaussian")
cosine <- density(pt, kernel="cosine")
gaussian
cosine
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5)); lines(gaussian, col="red"); lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5)); lines(gaussian, col="red");
lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5)); lines(gaussian, col="red");
lines(cosine, col="blue" add = TRUE); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5)); lines(gaussian, col="red");
lines(cosine, col="blue", add = TRUE); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
plot(lines(cosine)
plot(lines(cosine)
plot(lines(cosine);
plot(line(cosine);
plot(cosine);
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5)); lines(gaussian, col="red");
plot(cosine, col = "blue", add= TRUE);
plot(cosine, col = "blue", add=TRUE);
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5)); lines(gaussian, col="red");
ggplot(cosine, col = "blue", add=TRUE);
ggplot(data=Diamond, aes(carat, price/carat,colour=clarity)) + geom_point(size=1)
# overview of price carat and clarity
library(ggplot2)
set.seed(69)
library("StatDA")
library(ggplot2)
data(chorizon)
qpplot.das(pt, xlab = "pt")
qpplot.das(ptLog, xlab = "ptLog")
qpplot.das(ptRem, xlab = "ptRem")
qpplot.das(ptRemLog, xlab = "ptRemLog")
par(mfrow= c(2,2))
qpplot.das(pt, xlab = "pt")
qpplot.das(ptLog, xlab = "ptLog")
qpplot.das(ptRem, xlab = "ptRem")
qpplot.das(ptRemLog, xlab = "ptRemLog")
library("Ecdat")
data(Diamond)
clarity <- Diamond$clarity
carat <- Diamond$carat
price <- Diamond$price
clarity <- Diamond$clarity
carat <- Diamond$carat
price <- Diamond$price
Plotting of price and carat grouped by clarity shows that price and carat correlate. To eliminate this interference, price must be transformed to be independent from carat (weight).
Especially the clearer the diamonds get the smaller they are. Since this is the case the clearest diamonds (IF) seem to be the cheapest (because there are simply almost no large diamonds in IF).
``` {r}
ggplot(data=Diamond, aes(carat, price,colour=clarity)) + geom_point( size=1)
ggplot(data=Diamond, aes(carat, price,colour=clarity)) + geom_point( size=1)
gaussian <- density(pt, kernel= "gaussian")
cosine <- density(pt, kernel="cosine")
gaussian
cosine
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5)); lines(gaussian, col="red");
ggplot(cosine, col = "blue", add=TRUE);
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5)); lines(gaussian, col="red");
lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5)); lines(gaussian, col="red"); lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
gaussian
cosine
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5))
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5))
lines(gaussian, col="red"); lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
;
;
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5)); lines(gaussian, col="red"); lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability"); lines(gaussian, col="red"); lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability"); lines(gaussian, col="red");
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")
lines(gaussian, col="red");
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")
lines(gaussian, col="red");
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")
lines(gaussian, col="red")
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")
lines(gaussian, col="red")
lines(cosine, col="blue")
legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
window()
window(10)
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")
lines(gaussian, col="red")
lines(cosine, col="blue")
plot.new()
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")
plot.new()
lines(gaussian, col="red")
plot.new();lines(gaussian, col="red")
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")lines(gaussian, col="red")
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")lines(gaussian, col="red")
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability") lines(gaussian, col="red")
plot(gaussian, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")
plot(gaussian, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability"); lines(gaussian, col="red"); lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability"); lines(gaussian, col="red"); lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
plot(gaussian)
lines(cosine)
plot(gaussian)
lines(cosine)
plot(gaussian)
lines(cosine)
plot(gaussian)
lines(cosine)
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability"); lines(gaussian, col="red"); lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability");
lines(gaussian, col="red"); lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability");
lines(gaussian, col="red"); lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")
lines(gaussian, col="red")
lines(cosine, col="blue"); legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")
lines(gaussian, col="red")
lines(cosine, col="blue")
legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
set.seed(69)
library("StatDA")
library(ggplot2)
data(chorizon)
set.seed(69)
library("StatDA")
library(ggplot2)
data(chorizon)
---------------------------------------------------
# Examples:
## 1st Example:
### Histogram:
Histograms: a histogram is a graphical representation of numerical data. The data is divided into several bins that get drawn as rectangles according to the amount of data values contained in the bin.
The interval length can get calculated by several distinct formulas, e.g. Sturges or Freedman and Diaconis.
Histograms are used to get a broad overview of the given data to further analyze it with other tools.
Histogram for the given data (interval length from Sturges):
``` {r, echo=TRUE, eval=TRUE}
pt <- chorizon$Pt
length(pt) # amount of values
length(pt[pt %in% 0.25]) # amount of values = 0.25
ptRem <- pt[!pt %in% 0.25] # Removes the 0.25 values
ptRem <- ptRem[ptRem < 3] # Removes all values above 5
ptLog <- log(pt) # transforms to log()
ptRemLog <- log(ptRem) # transforms to log()
par(mfrow = c (2,2))
hist(pt)
hist(ptLog)
hist(ptRem)
hist(ptRemLog)
```
pt <- chorizon$Pt
length(pt) # amount of values
length(pt[pt %in% 0.25]) # amount of values = 0.25
ptRem <- pt[!pt %in% 0.25] # Removes the 0.25 values
ptRem <- ptRem[ptRem < 3] # Removes all values above 5
ptLog <- log(pt) # transforms to log()
ptRemLog <- log(ptRem) # transforms to log()
par(mfrow = c (2,2))
hist(pt)
hist(ptLog)
hist(ptRem)
hist(ptRemLog)
pt <- chorizon$Pt
length(pt) # amount of values
length(pt[pt %in% 0.25]) # amount of values = 0.25
ptRem <- pt[!pt %in% 0.25] # Removes the 0.25 values
ptRem <- ptRem[ptRem < 3] # Removes all values above 5
ptLog <- log(pt) # transforms to log()
ptRemLog <- log(ptRem) # transforms to log()
par(mfrow = c (2,2))
hist(pt)
hist(ptLog)
hist(ptRem)
hist(ptRemLog)
par(mfrow = c (2,2))
hist(pt, breaks="FD")
hist(ptLog, breaks="FD")
hist(ptRem, breaks="FD")
hist(ptRemLog, breaks="FD")
Here we can see the distribution more in depth. The interval length is small enough to see that most of the values not only lie between 0 and 2 but rather that over 300 of the values lie directly in the first interval (almost all having the value of 0.25 as we can see in the of "length(pt[pt %in% 0.25]".
The histogram of ptRemLog lets us see how this data could be transformed almost into a normal distribution (as we will be able to see with qpplot later) but at the cost of deleting several values (of 0.25 and above 3). As it is unlikely that the set has so many errors (more than half the data would be wrong) we will continue using the pt data (the original data without a log transformation).
Histogram for the given data (equidistant interval of 5 classes à length = 2)
``` {r, echo=TRUE, eval=TRUE }
br <- seq(0,10,2)
par(mfrow = c (1,2))
hist(pt[pt < 10], breaks=br)
hist(ptRem, breaks=br)
hist(pt[pt < 10], breaks=br, xlab="pt")
hist(ptRem, breaks=br)
gaussian <- density(pt, kernel= "gaussian")
cosine <- density(pt, kernel="cosine")
gaussian
cosine
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")
lines(gaussian, col="red")
lines(cosine, col="blue")
legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
par(mfrow= c(1,1))
plot(1,1, type="n", xlim=c(0,4), ylim=c(0,1.5), xlab="quantiles", ylab="probability")
lines(gaussian, col="red")
lines(cosine, col="blue")
legend(3,1.4, col = c("red", "blue"), legend=c("gaussian","cosine"),lty=c(1,1))
The cosine kernel would be more appropriate because there we can see the 'dip' between the many 0.25 values and the rest of the distribution that follows more of a normal distribution if transformed with log. On the gaussian kernel this fact is not included and would generate more generic datasets where this bump would be not as strong as in the cosine kernel.
On the other hand the gaussian kernel represents the extreme peak at 0.25 way more accurate than the cosine. Depending on the usecase both kernels have their own strengths for this dataset.
Below there are some extra qpplots to show the possibility of a normal distribution of the values in the interval (0.25,3].
``` {r}
par(mfrow= c(2,2))
qpplot.das(pt, xlab = "pt")
qpplot.das(ptLog, xlab = "ptLog")
qpplot.das(ptRem, xlab = "ptRem")
qpplot.das(ptRemLog, xlab = "ptRemLog")
library("Ecdat")
data(Diamond)
clarity <- Diamond$clarity
carat <- Diamond$carat
price <- Diamond$price
clarity <- Diamond$clarity
carat <- Diamond$carat
price <- Diamond$price
Plotting of price and carat grouped by clarity shows that price and carat correlate. To eliminate this interference, price must be transformed to be independent from carat (weight).
Especially the clearer the diamonds get the smaller they are. Since this is the case the clearest diamonds (IF) seem to be the cheapest (because there are simply almost no large diamonds in IF).
``` {r}
ggplot(data=Diamond, aes(carat, price,colour=clarity)) + geom_point( size=1)
ggplot(data=Diamond, aes(carat, price,colour=clarity), lab="test") + geom_point( size=1)
ggplot(data=Diamond, aes(carat, price,colour=clarity)) + geom_point( size=1) + ggtitle("test")
ggplot(data=Diamond, aes(carat, price,colour=clarity)) + geom_point( size=1) + ggtitle("Carat values of the diamonds plotted against price")
ggplot(data=Diamond, aes(carat, price,colour=clarity)) + geom_point( size=1) + ggtitle("Carat values of the diamonds plotted against price with color for clarity.")
ggplot(data=Diamond, aes(carat, price,colour=clarity))
+ geom_point( size=1)
+ geom_point( size=1)
+ ggtitle("Carat values of the diamonds plotted against price with color for clarity.")}
{ggplot(data=Diamond, aes(carat, price,colour=clarity))
+ geom_point( size=1)
+ ggtitle("Carat values of the diamonds plotted against price with color for clarity.")}
{ggplot(data=Diamond, aes(carat, price,colour=clarity))
+ geom_point( size=1)
+ ggtitle("Carat values of the diamonds plotted against price with color for clarity.")}
{ggplot(data=Diamond, aes(carat, price,colour=clarity)) +
geom_point( size=1)
+ ggtitle("Carat values of the diamonds plotted against price with color for clarity.")}
ggplot(data=Diamond, aes(carat, price,colour=clarity)) +
geom_point( size=1)
+ ggtitle("Carat values of the diamonds plotted against price with color for clarity.")
ggplot(data=Diamond, aes(carat, price,colour=clarity)) +
geom_point( size=1) +
ggtitle("Carat values of the diamonds plotted against price with color for clarity.")
ggplot(data=Diamond, aes(carat, price,colour=clarity)) +
geom_point( size=1) +
ggtitle("Carat values of the diamonds plotted against price with color for clarity.")
ggplot(data=Diamond, aes(carat, price,colour=clarity)) +
geom_point( size=1) +
ggtitle("Carat values of the diamonds plotted against price with color to show clarity.")
ggplot(data=Diamond, aes(carat, price,colour=clarity)) +
geom_point( size=1) +
ggtitle("Carat values of the diamonds plotted against price with color to show clarity.")
As we can see in the graph above, the price seems to increase quadratically compared to the amount of carats. Now 2 steps need to be done to make price independent of carat: we need to use price/carat as unit since the price goes up with every carat. Secondly we need need to remove the increase of price/carat. This comes from the lower supply for bigger diamonds. Since very clear diamonds are very rare for bigger sizes, they are way less common for higher carat sizes. To handle this problem we can divide another time by carat and get price/carat per carat which removes the influence of bigger diamonds being worth more per carat.
```{r}
ggplot(data=Diamond, aes(carat, price/carat,colour=clarity)) + geom_point(size=1)
ggplot(data=Diamond, aes(carat, price/carat,colour=clarity)) +
geom_point(size=1) +
ggtitle("price/carat plotted against carat")
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) +
geom_point( size=1) + geom_smooth(method='lm', se=FALSE) +
ggtitle("Final transformation to have constant values")
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) +
geom_point( size=1) + geom_smooth(method='lm', se=FALSE) +
ggtitle("Final transformation to have constant values")
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) +
geom_point( size=1) + geom_smooth(method='lm', se=FALSE) +
ggtitle("Final transformation to get constant values against carat")
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) +
geom_point( size=1) + geom_smooth(method='lm', se=FALSE) +
ggtitle("Final transformation to get constant values against carat (regression almost constant)")
boxplot(price ~ clarity,data = Diamond,  notch= TRUE)
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) +
geom_point( size=1) + geom_smooth(method='lm', se=FALSE) +
ggtitle("Final transformation to get constant values against carat (regression almost constant)")
boxplot(price ~ clarity,data = Diamond,  notch= TRUE)
par(mfrow= c(2,2))
qpplot.das(pt, xlab = "pt")
qpplot.das(ptLog, xlab = "ptLog")
qpplot.das(ptRem, xlab = "ptRem")
qpplot.das(ptRemLog, xlab = "ptRemLog")
par(mfrow= c(2,2))
qpplot.das(pt, xlab = "pt")
qpplot.das(ptLog, xlab = "ptLog")
qpplot.das(ptRem, xlab = "ptRem")
qpplot.das(ptRemLog, xlab = "ptRemLog")
## 2nd Example:
``` {r}
library("Ecdat")
data(Diamond)
clarity <- Diamond$clarity
carat <- Diamond$carat
price <- Diamond$price
clarity <- Diamond$clarity
carat <- Diamond$carat
price <- Diamond$price
Plotting of price and carat grouped by clarity shows that price and carat correlate. To eliminate this interference, price must be transformed to be independent from carat (weight).
Especially the clearer the diamonds get the smaller they are. Since this is the case the clearest diamonds (IF) seem to be the cheapest (because there are simply almost no large diamonds in IF).
``` {r}
ggplot(data=Diamond, aes(carat, price,colour=clarity)) +
geom_point( size=1) +
ggtitle("Carat values of the diamonds plotted against price with color to show clarity.")
# overview of price carat and clarity
par(mfrow = c(1,1))
ggplot(data=Diamond, aes(carat, price,colour=clarity)) +
geom_point( size=1) +
ggtitle("Carat values of the diamonds plotted against price with color to show clarity.")
ggplot(data=Diamond, aes(carat, price,colour=clarity)) +
geom_point( size=1) +
ggtitle("Carat values of the diamonds plotted against price with color to show clarity.")
As we can see in the graph above, the price seems to increase quadratically compared to the amount of carats. Now 2 steps need to be done to make price independent of carat: we need to use price/carat as unit since the price goes up with every carat. Secondly we need need to remove the increase of price/carat. This comes from the lower supply for bigger diamonds. Since very clear diamonds are very rare for bigger sizes, they are way less common for higher carat sizes. To handle this problem we can divide another time by carat and get price/carat per carat which removes the influence of bigger diamonds being worth more per carat.
```{r}
ggplot(data=Diamond, aes(carat, price/carat,colour=clarity)) +
geom_point(size=1) +
ggtitle("price/carat plotted against carat")
ggplot(data=Diamond, aes(carat, price/carat,colour=clarity)) +
geom_point(size=1) +
ggtitle("price/carat plotted against carat")
```{r}
ggplot(data=Diamond, aes(carat, price/carat,colour=clarity)) +
geom_point(size=1) +
ggtitle("price/carat plotted against carat")
```
Once we use price/carat we see that there is still an increase for bigger diamonds because they are way more rare than the cheaper ones. To remove this influence, we have to divide even more by carat. By doing this, we get the price/carat per carat^x which removes the increasing value/carat for bigger diamonds. X is in this case at about 0.6, as one can see in the graph below.
Below we can see the result of removing the quadratic influence of the weight: The price is now more or less constant over the whole length of carat (as can be seen by the linear regressions).
``` {r}
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) +
geom_point( size=1) + geom_smooth(method='lm', se=FALSE) +
ggtitle("Final transformation to get constant values against carat (regression almost constant)")
boxplot(price ~ clarity,data = Diamond,  notch= TRUE)
boxplot(price ~ clarity,data = Diamond,  notch= TRUE, lab="test")
boxplot(price ~ clarity,data = Diamond,  notch= TRUE, labtitle="test")
boxplot(price ~ clarity,data = Diamond,  notch= TRUE, main="Boxplot of price against price")
boxplot(price/carat~ clarity,data = Diamond,  notch= TRUE, main="")
boxplot(price/carat~ clarity,data = Diamond,  notch= TRUE, main="Boxplot of price/carat against clarity")
boxplot(log(price)/carat^1.6 ~ clarity, data = Diamond, notch= TRUE, main="Boxplot of price/(carat^1.6) against clarity")
ggplot(data=Diamond, aes(carat,(price/carat^1.6), colour=clarity)) +
geom_point( size=1) + geom_smooth(method='lm', se=FALSE) +
ggtitle("Final transformation to get constant values against carat (regression almost constant -> independent)")
``` {r}
bin <- rbinom(100, 94, 0.2)
norm <- rnorm(100,-1,7.4)
par(mfrow = c(1,1))
plot(ecdf(bin), col="blue", xlim=c(-20, 40)); lines(ecdf(norm), col="red"); legend(-20,1, col = c("red", "blue"), legend=c("norm","bin"),lty=c(1,1)); grid();
par(mfrow = c(1,1))
plot(ecdf(bin), col="blue", xlim=c(-20, 40)); lines(ecdf(norm), col="red")
legend(-20,1, col = c("red", "blue"), legend=c("norm","bin"),lty=c(1,1))
grid();
plot(ecdf(bin), col="blue", xlim=c(-20, 40), xlab="quantiles")
lines(ecdf(norm), col="red")
legend(-20,1, col = c("red", "blue"), legend=c("norm","bin"),lty=c(1,1))
plot(ecdf(bin), col="blue", xlim=c(-20, 40), xlab="quantiles", main="Estimated cumulative distribution function for norm and bin")
plot(ecdf(bin), col="blue", xlim=c(-20, 40), xlab="quantiles", ylab="Probability", main="Estimated cumulative distribution function for norm and bin")
lines(ecdf(norm), col="red")
legend(-20,1, col = c("red", "blue"), legend=c("norm","bin"),lty=c(1,1))
grid();
data(ohorizon)
na <- ohorizon$Na
as <- ohorizon$As
pb <- ohorizon$Pb
# Log transformations for all variables
na <- log(na)
as <- log(as)
pb <- log(pb)
# density plot
plot(density(na), col="green", xlim=c(-1,7), ylim=c(0,1)); lines(density(as), col="red"); lines(density(pb), col="blue"); legend(6,1,legend=c("na","as","pb"), col=c("green","red","blue"), lty=1);
# density plot
plot(density(na), col="green", xlim=c(-1,7), ylim=c(0,1)); lines(density(as), col="red"); lines(density(pb), col="blue"); legend(6,1,legend=c("na","as","pb"), col=c("green","red","blue"), lty=1);
# density plot
plot(density(na), col="green", xlim=c(-1,7), ylim=c(0,1))
lines(density(as), col="red")
lines(density(pb), col="blue")
legend(6,1,legend=c("na","as","pb"), col=c("green","red","blue"), lty=1);
# density plot
plot(density(na), col="green", xlim=c(-1,7), ylim=c(0,1), main="Estimated distribution functions")
# density plot
plot(density(na), col="green", xlim=c(-1,7), ylim=c(0,1), main="Estimated distribution functions", xlab="Quantiles", ylab="Probability")
lines(density(as), col="red")
lines(density(pb), col="blue")
legend(6,1,legend=c("na","as","pb"), col=c("green","red","blue"), lty=1);
# cdf plot
plot(ecdf(na), col="green", xlim=c(-1,7), ylim=c(0,1)); lines(ecdf(as), col="red"); lines(ecdf(pb), col="blue"); legend(5.5,0.4,legend=c("na","as","pb"), col=c("green","red","blue"), lty=1); grid();
# cdf plot
plot(ecdf(na), col="green", xlim=c(-1,7), ylim=c(0,1))
lines(ecdf(as), col="red"); lines(ecdf(pb), col="blue")
legend(5.5,0.4,legend=c("na","as","pb"), col=c("green","red","blue"), lty=1)
# cdf plot
plot(ecdf(na), col="green", xlim=c(-1,7), ylim=c(0,1), xlab="Quantiles", ylab="Probabilities", main="Estimated cumulative distribution functions")
lines(ecdf(as), col="red"); lines(ecdf(pb), col="blue")
legend(5.5,0.4,legend=c("na","as","pb"), col=c("green","red","blue"), lty=1)
grid();
sd(na)
sd(as)
sd(pb)
sd(na)
sd(as)
sd(pb)
The data got transformed to log since the samples have very high differences in the x-values. With the log transformation the differences are still visible while the readability of the samples is increased. The following description uses the log transformation. As we can see As has a similar distribution as Pb but the mean of As is at about 0.2, the mean of Pb is at about 3. The standard deviation of both as and pb seems to be similar.
Na on the other hand has a mean of about 4 and a way higher standard deviation.
All three have outliers in the upper bounds, especially As and Pb. Na has outliers in the lower bounds as well (a heavy tail).
## 4th Example:
``` {r}
x <- rnorm(500, -8, 2.06)
qqplot.das(x); grid();
qqplot.das(x, main="QQPlot of rnorm")
grid()
qqplot.das(na, ylim=c(-2,7), xlim=c(-3,3), col="green")
qqplot.das(as, add=TRUE, col="red")
qqplot.das(pb, add=TRUE, col="blue")
legend(-3,7,legend=c("na","as","pb"), col=c("green","red","blue"), lty=1)
grid();
qqplot.das(na, ylim=c(-2,7), xlim=c(-3,3), col="green", main="QQPlots of Elements against standard normal distribution")
qqplot.das(na, ylim=c(-2,7), xlim=c(-3,3), col="green", main="QQPlots of Elements against standard normal distribution", ylab="Quantiles of Element")
qqplot.das(as, add=TRUE, col="red")
qqplot.das(pb, add=TRUE, col="blue")
legend(-3,7,legend=c("na","as","pb"), col=c("green","red","blue"), lty=1)
grid();
